import os
import json
import re
import logging
import sqlite3
import uuid
import tiktoken
from typing import List, Dict, Any, Optional, Union, Callable
from datetime import datetime
import asyncio

from promptchain.utils.promptchaining import PromptChain
from promptchain.utils.agent_chain import AgentChain
from promptchain.utils.agentic_step_processor import AgenticStepProcessor

logger = logging.getLogger(__name__)

# Initialize tiktoken encoder
try:
    GPT4_ENCODER = tiktoken.encoding_for_model("gpt-4")
except Exception as e:
    logger.warning(f"Failed to initialize tiktoken encoder: {e}. Will use character-based estimation.")
    GPT4_ENCODER = None

def count_tokens(text: str) -> int:
    """
    Count the number of tokens in a text string using the GPT-4 tokenizer.
    Falls back to character-based estimation if tiktoken is not available.
    
    Args:
        text: The text to count tokens for
        
    Returns:
        The number of tokens in the text
    """
    if GPT4_ENCODER is not None:
        try:
            return len(GPT4_ENCODER.encode(text))
        except Exception as e:
            logger.warning(f"Error counting tokens with tiktoken: {e}. Falling back to character estimation.")
    
    # Fallback to character-based estimation (roughly 4 chars per token)
    return len(text) // 4

# Constants
STATE_AGENT_PROMPT = """
You are the State Agent, responsible for managing conversation sessions and history.
Your job is to help users locate, search, summarize, and manipulate previous conversations.

Key capabilities:
1. Search through conversation history to find relevant content
2. Identify and list sessions based on topics or keywords
3. Load previous sessions into the current conversation
4. Generate summaries of previous conversations
5. Remember and track session UUIDs you've interacted with

You have access to the following tools:
- list_sessions: List available sessions with optional filtering
- list_sessions_table: List available conversation sessions in a markdown table format with summaries
- search_conversations: Search for content across conversation sessions
- load_session: Load a specific session by UUID
- append_session: Add a session to the current conversation
- summarize_session: Generate a summary of a session
- compare_sessions: Analyze the relationship between multiple sessions

When interacting:
1. Understand the user's intent even if they use natural language
2. Maintain context about searches and sessions the user has performed
3. Take a step-by-step approach to complex tasks
4. Always confirm before making changes that affect the conversation state

Your internal memory allows you to reference sessions discovered in previous interactions.
For example, if a user asks to "summarize that session we talked about earlier", you should 
use your memory to identify which session they mean.

FORMAT YOUR RESPONSES:
- Use clear, concise language
- Organize search results in tables or bullet points
- For session summaries, organize by topic
- Include actionable options after each response (e.g., "Would you like to load this session?")

Remember: You are handling the user's conversation history, which may contain important information.
Be precise, helpful, and maintain context across interactions.
"""

class StateAgent(AgenticStepProcessor):
    """
    A specialized agent for managing conversation session state and history.
    This agent provides capabilities to search, load, and manipulate conversation histories
    across different sessions while maintaining its own memory of interactions.
    """
    
    # Tool schemas for AgenticStepProcessor
    TOOL_SCHEMAS = [
        {
            "type": "function",
            "function": {
                "name": "list_sessions",
                "description": "List available conversation sessions with optional filtering",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "filter_terms": {
                            "type": "string",
                            "description": "Optional keywords to filter sessions by topic"
                        },
                        "all_sessions": {
                            "type": "boolean",
                            "description": "Whether to include all sessions or just those we've interacted with"
                        },
                        "limit": {
                            "type": "integer",
                            "description": "Maximum number of sessions to return"
                        }
                    },
                    "required": []
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "list_sessions_table",
                "description": "List available conversation sessions in a markdown table format with summaries",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "filter_terms": {
                            "type": "string",
                            "description": "Optional keywords to filter sessions by topic"
                        },
                        "all_sessions": {
                            "type": "boolean",
                            "description": "Whether to include all sessions or just those we've interacted with"
                        },
                        "limit": {
                            "type": "integer",
                            "description": "Maximum number of sessions to return"
                        }
                    },
                    "required": []
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "search_conversations",
                "description": "Search across conversation sessions for specific content",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "search_terms": {
                            "type": "string",
                            "description": "Terms to search for in conversation content"
                        },
                        "search_all_instances": {
                            "type": "boolean",
                            "description": "Whether to search across all instances or just the current one"
                        },
                        "max_results": {
                            "type": "integer",
                            "description": "Maximum number of results to return"
                        }
                    },
                    "required": ["search_terms"]
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "load_session",
                "description": "Load a previous conversation session by its UUID",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "session_uuid": {
                            "type": "string",
                            "description": "UUID of the session to load"
                        },
                        "mode": {
                            "type": "string",
                            "description": "How to handle the loaded session",
                            "enum": ["replace_current", "append", "search_only"]
                        }
                    },
                    "required": ["session_uuid"]
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "summarize_session",
                "description": "Generate a summary of a specific conversation session",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "session_uuid": {
                            "type": "string",
                            "description": "UUID of the session to summarize"
                        }
                    },
                    "required": ["session_uuid"]
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "compare_sessions",
                "description": "Compare multiple sessions to identify relationships and common themes",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "session_uuids": {
                            "type": "array",
                            "items": {
                                "type": "string"
                            },
                            "description": "List of session UUIDs to compare"
                        }
                    },
                    "required": ["session_uuids"]
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "add_search_to_global_history",
                "description": "Add a search query and its results to the global conversation history",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "search_term": {
                            "type": "string",
                            "description": "Optional specific search term to add. If not provided, adds the most recent search."
                        }
                    },
                    "required": []
                }
            }
        }
    ]
    
    def __init__(self, agent_chain: AgentChain, verbose: bool = False):
        """
        Initialize the StateAgent with a reference to the AgentChain it will manipulate.
        
        Args:
            agent_chain: The AgentChain instance this agent will work with
            verbose: Whether to enable verbose logging
        """
        # Initialize the AgenticStepProcessor parent class
        super().__init__(
            objective=STATE_AGENT_PROMPT,
            max_internal_steps=7,
            model_name="openai/gpt-4o-mini",
            model_params={"temperature": 0.2, "tool_choice": "auto"}
        )
        
        self.agent_chain = agent_chain
        self.verbose = verbose
        self.internal_memory = {
            "known_sessions": [],  # Sessions we've discovered or interacted with
            "recent_searches": [],  # Recent search queries and results
            "session_summaries": {},  # Cached summaries of sessions
            "mini_summaries": {},  # Cached mini-summaries of sessions
            "last_mentioned_session": None,  # Most recently discussed session
        }
        
        # Ensure the agent chain has caching enabled
        if not self.agent_chain.enable_cache:
            logger.warning("StateAgent initialized with AgentChain that doesn't have caching enabled")
        
        logger.info("StateAgent initialized successfully")
    
    async def process_command(self, command: str) -> str:
        """
        Process a state agent command and return a response.
        
        Args:
            command: The command string from the user
            
        Returns:
            Response message after processing the command
        """
        # Log the incoming command
        if self.verbose:
            print(f"StateAgent processing command: {command}")
        logger.info(f"StateAgent processing command: {command}")
        
        # Check for specific command types using more flexible pattern matching
        
        # List sessions commands - expanded pattern matching
        if re.search(r"list.*sessions|show.*sessions|what.*sessions|list_recent_sessions|sessions.*list|recent.*sessions", command.lower()):
            return await self._handle_list_sessions(command)
            
        # Search commands
        elif re.search(r"find|search|look for|where did|about|conversations.*about", command.lower()):
            return await self._handle_search(command)
            
        # Load session commands
        elif re.search(r"load session|use session|switch to session|session.*load|^load\s+\w+", command.lower()):
            return await self._handle_load_session(command)
            
        # Append session commands
        elif re.search(r"add session|append session|include session|merge session", command.lower()):
            return await self._handle_append_session(command)
            
        # Add search to history command
        elif re.search(r"add search|save search|store search|add results|record search", command.lower()):
            # Extract the search term if specified
            search_term_match = re.search(r"for\s+['\"](.*?)['\"]|for\s+([\w\s]+)", command.lower())
            search_term = None
            if search_term_match:
                search_term = search_term_match.group(1) or search_term_match.group(2)
                search_term = search_term.strip()
            
            return await self.add_search_to_global_history(search_term)
            
        # Summarize commands
        elif re.search(r"summarize|summary|recap|sum up|brief|overview", command.lower()):
            # Check if it's a compare or inter-session summary request
            if re.search(r"relation|connect|related|between|across|compare", command.lower()):
                return await self._handle_compare_sessions(command)
            else:
                return await self._handle_summarize(command)
        
        # General/help command
        elif re.search(r"help|commands|what can you do|capabilities|features", command.lower()):
            help_text = """
I'm the State Agent, and I can help you manage your conversation history. Here are my main commands:

- **List Sessions**: `@state: list recent sessions` or `@state: list all sessions`
- **Search Content**: `@state: find conversations about [topic]` (search results are stored in my memory)
- **Add Search to History**: `@state: add search to history` (adds the most recent search to global history)
- **Summarize Sessions**: `@state: summarize session [ID]`
- **Load Sessions**: `@state: load session [ID]`
- **Compare Sessions**: `@state: compare sessions [ID1] and [ID2]`

You can use natural language for any of these commands. Just make sure to start with `@state:` to direct your message to me.

When you search for content, the results are stored in my internal memory but not automatically added to the conversation history. If you want to add search results to the global conversation history, use the "add search to history" command.
"""
            return help_text
            
        # General command processing using the LLM
        else:
            return await self._process_with_llm(command)
    
    async def _handle_search(self, command: str) -> str:
        """Handle search commands by finding relevant content in sessions."""
        # Extract search terms from command
        search_terms = re.sub(r"find|search|look for|where did|conversations about|we talk about", "", command.lower()).strip()
        
        if not search_terms:
            return "Please specify what you'd like to search for in the conversation history."
        
        # Search across all sessions
        search_results = self._search_sessions(search_terms, search_all_instances=True)
        
        if not search_results.get("success", False):
            return f"Error searching sessions: {search_results.get('error', 'Unknown error')}"
        
        # Track search in history (this updates both internal memory and global history)
        await self.track_search_in_history(search_terms, search_results)
        
        # If no matches were found
        if len(search_results.get("matches", [])) == 0:
            return f"I couldn't find any conversations about '{search_terms}'. Would you like to try a different search term?"
        
        # Format the search results
        matches = search_results.get("matches", [])
        
        # Group matches by session
        sessions = {}
        for match in matches:
            session_uuid = match.get("session_instance_uuid")
            if session_uuid not in sessions:
                sessions[session_uuid] = []
            sessions[session_uuid].append(match)
        
        # Format the response
        response_parts = [f"Found {len(matches)} matches for '{search_terms}' across {len(sessions)} sessions:"]
        
        for session_uuid, session_matches in sessions.items():
            # Store this session in known_sessions if not already there
            if session_uuid not in self.internal_memory["known_sessions"]:
                self.internal_memory["known_sessions"].append(session_uuid)
            
            # Set as last mentioned session
            self.internal_memory["last_mentioned_session"] = session_uuid
                
            response_parts.append(f"\n## Session ID: {session_uuid} ({len(session_matches)} matches)")
            
            # Get or generate a mini-summary for this session
            mini_summary = await self._get_or_generate_mini_summary(session_uuid)
            if mini_summary:
                response_parts.append(f"**Session Summary**: {mini_summary}")
            
            # Add a few sample matches from this session
            for i, match in enumerate(session_matches[:3]):  # Limit to 3 matches per session
                role = match.get("role", "")
                # Format role to show agent name if available
                if ":" in role and role.startswith("assistant:"):
                    role_parts = role.split(":", 1)
                    display_role = f"{role_parts[0]} ({role_parts[1]})"
                else:
                    display_role = role
                    
                timestamp = match.get("timestamp", "").split("T")[0]
                snippet = match.get("snippet", match.get("content", "")[:100] + "...")
                response_parts.append(f"{i+1}. **{display_role}** ({timestamp}): {snippet}")
            
            if len(session_matches) > 3:
                response_parts.append(f"...and {len(session_matches) - 3} more matches in this session.")
        
        response_parts.append("\nOptions:")
        response_parts.append("- Load a session: 'load session [Session ID]'")
        response_parts.append("- Summarize a session: 'summarize session [Session ID]'")
        response_parts.append("- Continue searching: 'search for [new terms]'")
        
        return "\n".join(response_parts)
    
    async def _handle_load_session(self, command: str) -> str:
        """Handle commands to load a specific session."""
        # Extract the session UUID from the command
        session_uuid_match = re.search(r"([0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12})", command)
        
        if not session_uuid_match:
            # Check if they're referring to "the session we just found" or similar
            if re.search(r"that session|the session|previous session|last session", command.lower()):
                # Use the last mentioned session from memory
                if self.internal_memory["last_mentioned_session"]:
                    session_uuid = self.internal_memory["last_mentioned_session"]
                else:
                    return "I don't have a specific session in mind. Please specify a session UUID or search for a session first."
            else:
                return "Please specify a valid session UUID to load, or search for sessions first."
        else:
            session_uuid = session_uuid_match.group(1)
        
        # Validate the session exists
        if not self._validate_session_exists(session_uuid):
            return f"Session with UUID {session_uuid} not found. Please check the UUID or search for available sessions."
        
        # Load the session using AgentChain's load_session method
        result = self._load_session(session_uuid, mode="replace_current")
        
        if not result.get("success", False):
            return f"Error loading session: {result.get('error', 'Unknown error')}"
        
        # Update internal memory
        if session_uuid not in self.internal_memory["known_sessions"]:
            self.internal_memory["known_sessions"].append(session_uuid)
        self.internal_memory["last_mentioned_session"] = session_uuid
        
        return f"Successfully loaded session {session_uuid}. Loaded {result.get('entries_loaded', 0)} conversation entries into the current context. You can now continue the conversation from this loaded session."
    
    async def _handle_append_session(self, command: str) -> str:
        """Handle commands to append a session to the current history."""
        # Extract the session UUID from the command
        session_uuid_match = re.search(r"([0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12})", command)
        
        if not session_uuid_match:
            # Check if they're referring to "the session we just found" or similar
            if re.search(r"that session|the session|previous session|last session", command.lower()):
                # Use the last mentioned session from memory
                if self.internal_memory["last_mentioned_session"]:
                    session_uuid = self.internal_memory["last_mentioned_session"]
                else:
                    return "I don't have a specific session in mind. Please specify a session UUID or search for a session first."
            else:
                return "Please specify a valid session UUID to append, or search for sessions first."
        else:
            session_uuid = session_uuid_match.group(1)
        
        # Validate the session exists
        if not self._validate_session_exists(session_uuid):
            return f"Session with UUID {session_uuid} not found. Please check the UUID or search for available sessions."
        
        # Append the session using AgentChain's load_session method
        result = self._load_session(session_uuid, mode="append")
        
        if not result.get("success", False):
            return f"Error appending session: {result.get('error', 'Unknown error')}"
        
        # Update internal memory
        if session_uuid not in self.internal_memory["known_sessions"]:
            self.internal_memory["known_sessions"].append(session_uuid)
        self.internal_memory["last_mentioned_session"] = session_uuid
        
        return f"Successfully appended session {session_uuid}. Added {result.get('entries_loaded', 0)} conversation entries to the current context. The current conversation now includes content from both sessions."
    
    async def _handle_list_sessions(self, command: str) -> str:
        """Handle list sessions commands by returning a formatted list of available sessions."""
        # Extract filter terms if present
        filter_terms = re.sub(r"list sessions|show sessions|what sessions|list_recent_sessions|list recent sessions", "", command.lower()).strip()
        
        # Determine if we want all sessions
        all_sessions = "all" in command.lower()
        
        # Default limit
        limit = 10
        if re.search(r"show (\d+)|list (\d+)", command.lower()):
            limit_match = re.search(r"show (\d+)|list (\d+)", command.lower())
            if limit_match:
                limit = int(limit_match.group(1) or limit_match.group(2))
        
        # Get the sessions
        sessions_result = self._list_sessions(
            topic_filter=filter_terms if filter_terms else None,
            all_sessions=all_sessions,
            limit=limit
        )
        
        if not sessions_result.get("success", False):
            return f"Error listing sessions: {sessions_result.get('error', 'Unknown error')}"
        
        sessions = sessions_result.get("sessions", [])
        
        # If no sessions found
        if not sessions:
            return "No sessions found. This may be because no conversations have been cached yet."
        
        # Format the response
        response_parts = [f"Found {len(sessions)} session{'s' if len(sessions) > 1 else ''}:"]
        
        for i, session in enumerate(sessions, 1):
            session_uuid = session.get("session_instance_uuid", "unknown")
            created_at = session.get("created_at", "unknown date")
            # Try to get a simple date
            if "T" in created_at:
                created_at = created_at.split("T")[0]
            
            # Add this session to known sessions
            if session_uuid not in self.internal_memory["known_sessions"]:
                self.internal_memory["known_sessions"].append(session_uuid)
            
            # Get or generate mini summary
            mini_summary = "No summary available"
            if session_uuid in self.internal_memory["mini_summaries"]:
                mini_summary = self.internal_memory["mini_summaries"][session_uuid]
            else:
                # Generate async in the background if possible
                asyncio.create_task(self._get_or_generate_mini_summary(session_uuid))
            
            # Format entry - show full UUID and make it clear this is the session ID
            response_parts.append(f"\n{i}. **Session ID**: {session_uuid} ({created_at})")
            
            # Add mini summary if available
            if mini_summary:
                response_parts.append(f"   **Content**: {mini_summary}")
            
            # Add message count if available
            message_count = session.get("message_count", 0)
            if message_count:
                response_parts.append(f"   **Messages**: {message_count}")
        
        # Add actions
        response_parts.append("\n**Actions you can take:**")
        response_parts.append("- Load a session: `@state: load session [Session ID]`")
        response_parts.append("- Summarize a session: `@state: summarize session [Session ID]`")
        response_parts.append("- Search within these sessions: `@state: find conversations about [topic]`")
        
        return "\n".join(response_parts)
    
    async def _handle_summarize(self, command: str) -> str:
        """Handle commands to summarize a session."""
        # Extract the session UUID from the command
        session_uuid_match = re.search(r"([0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12})", command)
        
        if not session_uuid_match:
            # Check if they're referring to "the session we just found" or similar
            if re.search(r"that session|the session|previous session|last session", command.lower()):
                # Use the last mentioned session from memory
                if self.internal_memory["last_mentioned_session"]:
                    session_uuid = self.internal_memory["last_mentioned_session"]
                else:
                    return "I don't have a specific session in mind. Please specify a session UUID or search for a session first."
            else:
                return "Please specify a valid session UUID to summarize, or search for sessions first."
        else:
            session_uuid = session_uuid_match.group(1)
        
        # Validate the session exists
        if not self._validate_session_exists(session_uuid):
            return f"Session with UUID {session_uuid} not found. Please check the UUID or search for available sessions."
        
        # Check if we already have a cached summary
        if session_uuid in self.internal_memory["session_summaries"]:
            cached_summary = self.internal_memory["session_summaries"][session_uuid]
            # Check if the cached summary is recent (within the last hour)
            cache_time = datetime.fromisoformat(cached_summary.get("timestamp", "2000-01-01T00:00:00"))
            if (datetime.now() - cache_time).total_seconds() < 3600:  # Less than an hour old
                return cached_summary.get("summary", "Summary not available.")
        
        # Get the session data in search_only mode
        session_data = self._load_session(session_uuid, mode="search_only")
        
        if not session_data.get("success", False):
            return f"Error retrieving session data: {session_data.get('error', 'Unknown error')}"
        
        # Update internal memory
        if session_uuid not in self.internal_memory["known_sessions"]:
            self.internal_memory["known_sessions"].append(session_uuid)
        self.internal_memory["last_mentioned_session"] = session_uuid
        
        # Generate a summary using the LLM
        entries = session_data.get("entries", [])
        
        if not entries:
            return f"Session {session_uuid} exists but contains no conversation entries."
        
        # Format the conversation for summarization
        conversation = []
        total_tokens = 0
        max_tokens = 16000  # Token limit for context
        
        for entry in entries:
            role = entry.get("role", "")
            # Format role to show agent name if available
            if ":" in role and role.startswith("assistant:"):
                role_parts = role.split(":", 1)
                display_role = f"{role_parts[0]} ({role_parts[1]})"
            else:
                display_role = role
            
            content = entry.get("content", "")
            message_text = f"{display_role}: {content}"
            
            # Count tokens for this message
            message_tokens = count_tokens(message_text)
            
            # Check if adding this message would exceed token limit
            if total_tokens + message_tokens > max_tokens:
                # Add a note about truncation
                conversation.append("...\n[Conversation truncated due to length]")
                break
            
            conversation.append(message_text)
            total_tokens += message_tokens
        
        conversation_text = "\n\n".join(conversation)
        logger.info(f"Summarizing session {session_uuid} with {total_tokens} tokens from {len(conversation)} messages")
        
        # Generate the summary with the LLM
        summarization_prompt = f"""
Please provide a concise summary of the following conversation session.
Focus on:
1. Main topics discussed
2. Key questions asked and answers provided
3. Any decisions or conclusions reached
4. Technical concepts or code examples mentioned
5. DO NOT focus on greetings - only substantive content

Format the summary with clear sections and bullet points where appropriate.

CONVERSATION SESSION {session_uuid}:
{conversation_text}

SUMMARY:
"""
        
        # Use a separate PromptChain for summarization to avoid confusing the agentic step processor
        summarizer = PromptChain(
            models=[{"name": "openai/gpt-4o-mini", "params": {"temperature": 0.2}}],
            instructions=[summarization_prompt],
            verbose=self.verbose
        )
        
        summary_response = await summarizer.process_prompt_async("")
        
        # Cache the summary in memory
        self.internal_memory["session_summaries"][session_uuid] = {
            "timestamp": datetime.now().isoformat(),
            "summary": summary_response,
            "message_count": len(entries)
        }
        
        # Append options to the summary
        full_response = summary_response + "\n\nOptions:\n- Load this session: 'load session " + session_uuid + "'\n- Continue with current session: 'continue'\n- Search for related sessions: 'search for [terms]'"
        
        return full_response
    
    async def _handle_compare_sessions(self, command: str) -> str:
        """Handle commands to compare sessions and summarize relationships between them."""
        # Extract session UUIDs from the command
        # Look for multiple UUIDs in the command
        uuid_matches = re.findall(r"([0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12})", command)
        
        # If we don't have at least 2 UUIDs, check if we're referring to recent sessions
        if len(uuid_matches) < 2:
            # Check if they want to compare recently mentioned sessions
            if re.search(r"recent|latest|previous", command.lower()):
                # Use the most recent sessions from internal memory
                known_sessions = self.internal_memory["known_sessions"]
                if len(known_sessions) >= 2:
                    uuid_matches = known_sessions[-2:]  # Use the 2 most recent
                else:
                    return "I need at least 2 sessions to compare. Please specify session UUIDs or search for sessions first."
        
        # Validate all sessions exist
        for session_uuid in uuid_matches:
            if not self._validate_session_exists(session_uuid):
                return f"Session with UUID {session_uuid} not found. Please check the UUID or search for available sessions."
        
        # Compare the sessions
        comparison = self._compare_sessions(uuid_matches)
        
        if not comparison.get("success", False):
            return f"Error comparing sessions: {comparison.get('error', 'Unknown error')}"
        
        # Update internal memory to include all sessions being compared
        for session_uuid in uuid_matches:
            if session_uuid not in self.internal_memory["known_sessions"]:
                self.internal_memory["known_sessions"].append(session_uuid)
        
        # Generate a comprehensive inter-session summary using the LLM
        session_summaries = []
        
        for session_uuid in uuid_matches:
            # Get a summary for each session
            mini_summary = await self._get_or_generate_mini_summary(session_uuid)
            uuid_short = session_uuid[:8]
            session_summaries.append(f"- Session {uuid_short}...: {mini_summary}")
        
        relationships = comparison.get("relationships", [])
        common_terms = comparison.get("common_terms", [])
        
        inter_session_summarization_prompt = f"""
Please analyze the relationship between these conversation sessions and provide a concise summary of how they connect.

SESSION SUMMARIES:
{chr(10).join(session_summaries)}

IDENTIFIED RELATIONSHIPS:
{chr(10).join([rel.get("description", "") for rel in relationships])}

COMMON THEMES:
{', '.join(common_terms[:10]) if common_terms else 'No common themes identified'}

Provide a brief (3-5 sentences) analysis of how these sessions relate to each other and what insights might be gained by considering them together. Include mentions of progression, thematic connections, or contextual relationships.

INTER-SESSION ANALYSIS:
"""
        
        # Use a separate PromptChain for the inter-session analysis
        analyzer = PromptChain(
            models=[{"name": "openai/gpt-4o-mini", "params": {"temperature": 0.2}}],
            instructions=[inter_session_summarization_prompt],
            verbose=self.verbose
        )
        
        inter_session_summary = await analyzer.process_prompt_async("")
        
        # Format the response
        response_parts = [f"# Comparison of {len(uuid_matches)} Sessions"]
        
        # Add the mini-summaries
        response_parts.append("\n## Session Summaries:")
        for summary in session_summaries:
            response_parts.append(summary)
        
        # Add the inter-session analysis
        response_parts.append("\n## Relationship Analysis:")
        response_parts.append(inter_session_summary)
        
        # Add common themes if any
        if common_terms:
            response_parts.append("\n## Common Themes:")
            response_parts.append(f"Common topics across sessions: {', '.join(common_terms[:10])}")
        
        # Add chronological relationship if available
        for relationship in relationships:
            if relationship.get("type") == "chronological" and "order" in relationship:
                response_parts.append("\n## Chronological Order:")
                chronology = relationship.get("order", [])
                for i, entry in enumerate(chronology):
                    uuid = entry.get("uuid", "")
                    created_at = entry.get("created_at", "").split("T")[0]
                    response_parts.append(f"{i+1}. Session {uuid[:8]}... (Created: {created_at})")
        
        response_parts.append("\nOptions:")
        response_parts.append("- Load a session: 'load session [UUID]'")
        response_parts.append("- Search within these sessions: 'search for [terms]'")
        
        return "\n".join(response_parts)
    
    async def _process_with_llm(self, command: str) -> str:
        """Process commands that don't match specific patterns using the LLM."""
        # Check for table formatting requests - handle lots of variations
        table_pattern = r"table|markdown|md|tabular|structur|as a table"
        list_pattern = r"list.*sessions|show.*sessions|sessions.*list|recent.*sessions|what.*sessions|sessions.*can you"
        
        if re.search(table_pattern, command.lower()) and re.search(list_pattern, command.lower()):
            return await self.get_sessions_markdown_table()
            
        # Check for list command patterns first since they're common
        if re.search(r"list.*sessions|show.*sessions|sessions.*list|recent.*sessions|available.*sessions|list_recent_sessions", command.lower()):
            return await self._handle_list_sessions(command)
            
        # For general commands, update internal memory representation
        internal_memory_str = json.dumps(self.internal_memory, indent=2)
        
        prompt = f"""
Command from user: "{command}"

Your internal memory state:
{internal_memory_str}

Analyze this command in the context of your role as a State Agent. 
If it's related to session management, history search, or conversation state,
respond appropriately.

If you need to perform a specific operation like searching or loading sessions,
explain what you would do and what the expected outcome would be.

If this doesn't seem like a command for the State Agent, explain that you're
specialized in managing conversation history and sessions, and suggest some
relevant commands the user might want to try.
"""
        
        try:
            response = await self.prompt_chain.process_prompt_async(prompt)
            
            # Add some action suggestions if not already present
            if "you can" not in response.lower() and "available commands" not in response.lower():
                response += "\n\nHere are some commands you can use:\n"
                response += "- Search for content: `@state: find conversations about X`\n"
                response += "- List sessions: `@state: list recent sessions`\n"
                response += "- Summarize a session: `@state: summarize session [ID]`\n"
                response += "- Load a session: `@state: load session [ID]`"
                
            return response
        except Exception as e:
            logger.error(f"Error processing command with LLM: {e}")
            return f"I encountered an error processing your command: {e}. Please try again with a more specific command like 'list recent sessions' or 'find conversations about [topic]'."
    
    def _search_sessions(self, query: str, search_all_instances: bool = True, max_results: int = 20) -> Dict[str, Any]:
        """
        Search across conversation sessions for content matching the query.
        
        Args:
            query: Search terms to look for in conversation content
            search_all_instances: Whether to search across all sessions or just the current one
            max_results: Maximum number of matching entries to return
            
        Returns:
            Dict with search results and metadata
        """
        if not self.agent_chain.enable_cache:
            return {"success": False, "error": "Cache is not enabled", "matches": []}
            
        if not self.agent_chain.db_connection:
            return {"success": False, "error": "Database connection not established", "matches": []}
            
        try:
            cursor = self.agent_chain.db_connection.cursor()
            
            # Get the database name
            db_name = self.agent_chain.cache_config.get("name", "default")
            
            # Prepare query condition based on search_all_instances flag
            instance_condition = ""
            params = [f"%{query}%", f"%{query}%", db_name]
            
            if not search_all_instances:
                instance_condition = "AND session_instance_uuid = ?"
                params.append(self.agent_chain.session_instance_uuid)
            
            # Search for matching content
            cursor.execute(
                f"""
                SELECT session_instance_uuid, role, content, timestamp 
                FROM conversation_entries 
                WHERE (content LIKE ? OR role LIKE ?) 
                AND session_id = ? 
                {instance_condition}
                ORDER BY id DESC
                LIMIT ?
                """,
                params + [max_results]
            )
            
            matches = []
            for session_uuid, role, content, timestamp in cursor.fetchall():
                matches.append({
                    "session_instance_uuid": session_uuid,
                    "role": role,
                    "content": content,
                    "timestamp": timestamp,
                    # Include a snippet around the matching part
                    "snippet": self._extract_snippet(content, query, context_chars=100)
                })
                    
            return {
                "success": True,
                "query": query,
                "search_all_instances": search_all_instances,
                "matches_found": len(matches),
                "matches": matches
            }
            
        except Exception as e:
            logger.error(f"Error searching sessions: {e}")
            return {"success": False, "error": str(e), "matches": []}
    
    def _extract_snippet(self, text: str, query: str, context_chars: int = 100) -> str:
        """Extract a snippet of text around the query match with context."""
        if not query or not text:
            return text[:200] + "..." if len(text) > 200 else text
            
        query_lower = query.lower()
        text_lower = text.lower()
        
        # Find position of the query in the text
        pos = text_lower.find(query_lower)
        if pos == -1:
            # If exact match not found, return start of text
            return text[:200] + "..." if len(text) > 200 else text
        
        # Calculate start and end positions for snippet
        start = max(0, pos - context_chars)
        end = min(len(text), pos + len(query) + context_chars)
        
        # Add ellipsis if the snippet doesn't start or end at the text boundaries
        prefix = "..." if start > 0 else ""
        suffix = "..." if end < len(text) else ""
        
        return prefix + text[start:end] + suffix
    
    def _load_session(self, session_uuid: str, mode: str = "replace_current", max_entries: int = None) -> Dict[str, Any]:
        """
        Load a previous conversation session by its UUID.
        Wrapper around the agent_chain's similar functionality.
        
        Args:
            session_uuid: The UUID of the session to load
            mode: How to handle the loaded session ('replace_current', 'append', 'search_only')
            max_entries: Maximum number of entries to load (newest first if limited)
            
        Returns:
            Dict with operation results including success status and loaded entries
        """
        if not self.agent_chain.enable_cache:
            return {"success": False, "error": "Cache is not enabled", "entries_loaded": 0}
            
        if not self.agent_chain.db_connection:
            return {"success": False, "error": "Database connection not established", "entries_loaded": 0}
            
        try:
            cursor = self.agent_chain.db_connection.cursor()
            
            # Get the database name
            db_name = self.agent_chain.cache_config.get("name", "default")
            
            # Verify the session exists
            cursor.execute(
                "SELECT session_id FROM sessions WHERE session_instance_uuid = ?",
                (session_uuid,)
            )
            session_result = cursor.fetchone()
            
            if not session_result:
                return {"success": False, "error": f"Session with ID {session_uuid} not found", "entries_loaded": 0}
            
            # Get conversation entries for the specified session
            query = """
            SELECT role, content, timestamp 
            FROM conversation_entries 
            WHERE session_id = ? AND session_instance_uuid = ? 
            ORDER BY id
            """
            params = (db_name, session_uuid)
            
            if max_entries:
                # Add LIMIT to the query if max_entries is specified
                query += f" LIMIT {int(max_entries)}"
                
            cursor.execute(query, params)
            entries = []
            
            for role, content, timestamp in cursor.fetchall():
                entries.append({"role": role, "content": content, "timestamp": timestamp})
            
            # Handle the loaded entries based on mode
            if mode == "replace_current":
                # Clear current history and replace with loaded session
                self.agent_chain._conversation_history = entries
                if self.verbose:
                    print(f"Replaced current history with {len(entries)} entries from session {session_uuid}")
                    
            elif mode == "append":
                # Append loaded entries to current history
                self.agent_chain._conversation_history.extend(entries)
                if self.verbose:
                    print(f"Appended {len(entries)} entries from session {session_uuid} to current history")
                    
            # For search_only mode, we don't modify the history
            
            return {
                "success": True, 
                "entries_loaded": len(entries),
                "session_id": db_name,
                "session_uuid": session_uuid,
                "mode": mode,
                "entries": entries if mode == "search_only" else None
            }
            
        except Exception as e:
            logger.error(f"Error loading session {session_uuid}: {e}")
            return {"success": False, "error": str(e), "entries_loaded": 0}
    
    def _list_sessions(self, topic_filter: Optional[str] = None, all_sessions: bool = True, limit: int = 10) -> Dict[str, Any]:
        """
        List available sessions, optionally filtered by topic.
        
        Args:
            topic_filter: Optional keyword to filter sessions by topic
            all_sessions: Whether to include all sessions or just those we've interacted with
            limit: Maximum number of sessions to return
            
        Returns:
            Dict with list of sessions and metadata
        """
        if not self.agent_chain.enable_cache:
            return {"success": False, "error": "Cache is not enabled", "sessions": []}
            
        if not self.agent_chain.db_connection:
            return {"success": False, "error": "Database connection not established", "sessions": []}
            
        try:
            cursor = self.agent_chain.db_connection.cursor()
            
            # Get the session ID for the current database (used as a filter)
            db_name = self.agent_chain.cache_config.get("name", "default")
            
            # Build the query based on filters
            if not all_sessions and not self.internal_memory["known_sessions"]:
                # If we're limited to known sessions but there are none
                return {"success": True, "sessions": [], "count": 0}
                
            if not all_sessions:
                # Filter to only include sessions we know about
                placeholders = ",".join(["?"] * len(self.internal_memory["known_sessions"]))
                query = f"""
                SELECT s.session_instance_uuid, s.created_at, COUNT(c.id) as message_count
                FROM sessions s
                LEFT JOIN conversation_entries c ON s.session_id = c.session_id AND s.session_instance_uuid = c.session_instance_uuid
                WHERE s.session_id = ? AND s.session_instance_uuid IN ({placeholders})
                GROUP BY s.session_instance_uuid
                ORDER BY s.created_at DESC
                LIMIT ?
                """
                params = [db_name] + self.internal_memory["known_sessions"] + [limit]
            else:
                # Include all sessions for this session_id
                query = """
                SELECT s.session_instance_uuid, s.created_at, COUNT(c.id) as message_count
                FROM sessions s
                LEFT JOIN conversation_entries c ON s.session_id = c.session_id AND s.session_instance_uuid = c.session_instance_uuid
                WHERE s.session_id = ?
                GROUP BY s.session_instance_uuid
                ORDER BY s.created_at DESC
                LIMIT ?
                """
                params = [db_name, limit]
                
            cursor.execute(query, params)
            sessions = []
            
            for uuid, created_at, message_count in cursor.fetchall():
                session_data = {
                    "session_instance_uuid": uuid,
                    "created_at": created_at,
                    "message_count": message_count
                }
                
                # If we have a topic filter, check if this session contains it
                if topic_filter:
                    # Get a sample of messages from this session to check for topic
                    cursor.execute(
                        """
                        SELECT role, content
                        FROM conversation_entries
                        WHERE session_id = ? AND session_instance_uuid = ?
                        ORDER BY id
                        LIMIT 5
                        """,
                        (db_name, uuid)
                    )
                    
                    session_content = []
                    for role, content in cursor.fetchall():
                        session_content.append(content)
                        
                    # Check if any content contains the topic
                    combined_content = " ".join(session_content).lower()
                    if topic_filter.lower() not in combined_content:
                        continue  # Skip this session if topic not found
                    
                    # Add topic relevance info
                    session_data["topic_relevance"] = "Contains topic: " + topic_filter
                
                # Get a sample message from this session
                cursor.execute(
                    """
                    SELECT role, content
                    FROM conversation_entries
                    WHERE session_id = ? AND session_instance_uuid = ?
                    ORDER BY id
                    LIMIT 1
                    """,
                    (db_name, uuid)
                )
                
                sample = cursor.fetchone()
                if sample:
                    session_data["sample_message"] = {
                        "role": sample[0],
                        "content": sample[1]
                    }
                
                sessions.append(session_data)
            
            return {
                "success": True,
                "sessions": sessions,
                "count": len(sessions),
                "topic_filter": topic_filter,
                "all_sessions": all_sessions
            }
            
        except Exception as e:
            logger.error(f"Error listing sessions: {e}")
            return {"success": False, "error": str(e), "sessions": []}
    
    def _validate_session_exists(self, session_uuid: str) -> bool:
        """Check if a session with the given UUID exists in the database."""
        if not self.agent_chain.enable_cache or not self.agent_chain.db_connection:
            return False
            
        try:
            cursor = self.agent_chain.db_connection.cursor()
            
            cursor.execute(
                "SELECT COUNT(*) FROM sessions WHERE session_instance_uuid = ?",
                (session_uuid,)
            )
            
            count = cursor.fetchone()[0]
            return count > 0
            
        except Exception as e:
            logger.error(f"Error validating session existence: {e}")
            return False

    @property
    def prompt_chain(self) -> PromptChain:
        """
        Create a simple PromptChain for summarization tasks.
        This is needed because we removed the dedicated prompt_chain in the refactoring.
        
        Returns:
            A configured PromptChain for text summarization
        """
        # Create a new PromptChain with the same model as the AgenticStepProcessor
        return PromptChain(
            models=[{"name": self.model_name, "params": {"temperature": 0.2}}],
            instructions=[""],  # Empty instruction since we'll provide full prompts
            verbose=self.verbose
        )
        
    async def _get_or_generate_mini_summary(self, session_uuid: str) -> str:
        """
        Get a cached mini-summary or generate a new one for the specified session.
        Analyzes a substantial portion of the conversation to create a meaningful summary.
        
        Args:
            session_uuid: UUID of the session to summarize
            
        Returns:
            A brief 1-2 sentence summary of the session content
        """
        # Check if we already have a cached mini-summary
        if session_uuid in self.internal_memory["mini_summaries"]:
            cached_summary = self.internal_memory["mini_summaries"][session_uuid]
            # Check if the cached summary is recent (within the last day)
            if isinstance(cached_summary, dict) and "timestamp" in cached_summary:
                cache_time = datetime.fromisoformat(cached_summary.get("timestamp", "2000-01-01T00:00:00"))
                if (datetime.now() - cache_time).total_seconds() < 86400:  # Less than a day old
                    summary = cached_summary.get("summary", "")
                    # Don't return generic greeting messages as summaries - stricter check
                    if any(greeting in summary.lower() for greeting in ["initial greeting", "hello", "hi there", "welcome"]) and len(summary) < 100:
                        pass  # Fall through to generate a new summary
                    else:
                        return summary
        
        # Get messages from the session to generate a summary
        if not self.agent_chain.enable_cache or not self.agent_chain.db_connection:
            return "No database connection available"
            
        try:
            cursor = self.agent_chain.db_connection.cursor()
            
            # Get the database name
            db_name = self.agent_chain.cache_config.get("name", "default")
            
            # First check how many messages are in the session
            cursor.execute(
                """
                SELECT COUNT(*) 
                FROM conversation_entries 
                WHERE session_id = ? AND session_instance_uuid = ?
                """,
                (db_name, session_uuid)
            )
            
            count_result = cursor.fetchone()
            message_count = count_result[0] if count_result else 0
            
            if message_count == 0:
                return "Empty session"
            
            # For sessions with more messages, analyze messages from different parts of the conversation
            # to get a more representative view (beginning, middle, and end)
            sampling_strategy = ""
            if message_count <= 20:
                # For small conversations, get all messages
                query = """
                SELECT role, content 
                FROM conversation_entries 
                WHERE session_id = ? AND session_instance_uuid = ? 
                ORDER BY id
                """
                params = (db_name, session_uuid)
                sampling_strategy = "all messages"
            else:
                # For longer conversations, get a representative sample
                # Get first 10 messages, 10 from the middle, and last 10 messages
                query = """
                SELECT role, content 
                FROM conversation_entries 
                WHERE session_id = ? AND session_instance_uuid = ? 
                ORDER BY id
                LIMIT 10
                
                UNION ALL
                
                SELECT role, content 
                FROM conversation_entries 
                WHERE session_id = ? AND session_instance_uuid = ? 
                ORDER BY id
                LIMIT 10 OFFSET ?
                
                UNION ALL
                
                SELECT role, content 
                FROM conversation_entries 
                WHERE session_id = ? AND session_instance_uuid = ? 
                ORDER BY id DESC
                LIMIT 10
                """
                middle_offset = max(10, message_count // 2 - 5)  # Get messages from around the middle
                params = (db_name, session_uuid, db_name, session_uuid, middle_offset, db_name, session_uuid)
                sampling_strategy = f"30 messages (10 beginning, 10 middle at offset {middle_offset}, 10 end)"
            
            cursor.execute(query, params)
            messages = cursor.fetchall()
            
            # Format the conversation for summarization
            conversation_sample = []
            total_tokens = 0
            target_tokens = 15000  # Target tokens (slightly less than 16k to leave room for the prompt)
            max_tokens_per_message = target_tokens // len(messages) if messages else 1000  
            
            logger.info(f"Processing {len(messages)} messages ({sampling_strategy}) for summary of session {session_uuid}")
            
            # Process messages to create a representative sample
            for role, content in messages:
                # Format role to show agent name if available
                if ":" in role and role.startswith("assistant:"):
                    role_parts = role.split(":", 1)
                    display_role = f"{role_parts[0]} ({role_parts[1]})"
                else:
                    display_role = role
                
                # Truncate very long messages to avoid one message dominating the sample
                token_count = count_tokens(content)
                if token_count > max_tokens_per_message:
                    # If this message is very large, only include a portion
                    if GPT4_ENCODER is not None:
                        # If we have tiktoken, use it for precise truncation
                        try:
                            tokens = GPT4_ENCODER.encode(content)
                            truncated_content = GPT4_ENCODER.decode(tokens[:max_tokens_per_message])
                            content = truncated_content + "..."
                        except Exception as e:
                            # Fall back to character-based approximation
                            content = content[:max_tokens_per_message * 4] + "..."
                    else:
                        # Fall back to character-based approximation
                        content = content[:max_tokens_per_message * 4] + "..."
                
                # Add this message
                message_text = f"{display_role}: {content}"
                message_tokens = count_tokens(message_text)
                
                # Check if adding this message would exceed our token limit
                if total_tokens + message_tokens > target_tokens:
                    # If we're already over half the limit, we have enough context
                    if total_tokens > (target_tokens / 2):
                        break
                    # Otherwise truncate the message to fit
                    available_tokens = target_tokens - total_tokens
                    if available_tokens > 100:  # Only truncate if we can keep a meaningful portion
                        if GPT4_ENCODER is not None:
                            try:
                                tokens = GPT4_ENCODER.encode(message_text)
                                truncated_text = GPT4_ENCODER.decode(tokens[:available_tokens])
                                conversation_sample.append(truncated_text + "...")
                            except Exception:
                                # Fall back to character-based approximation
                                truncated_text = message_text[:int(4 * available_tokens)]
                                conversation_sample.append(truncated_text + "...")
                        else:
                            truncated_text = message_text[:int(4 * available_tokens)]
                            conversation_sample.append(truncated_text + "...")
                        total_tokens += available_tokens
                    break
                
                conversation_sample.append(message_text)
                total_tokens += message_tokens
            
            conversation_text = "\n\n".join(conversation_sample)
            logger.info(f"Generated context for summary with {total_tokens} tokens from {len(conversation_sample)} messages")
            
            # Improved detection of substantive content vs. just greetings
            # Only consider it "greetings only" if ALL messages are very short and ALL contain greetings
            greeting_phrases = ["hello", "hi there", "welcome", "how can i assist", "how may i help"]
            
            # Check if ALL messages are greetings (not just some)
            if message_count <= 5:
                all_greetings = True
                for msg in conversation_sample:
                    # If ANY message is longer than 100 chars or doesn't contain a greeting, it's not "greetings only"
                    msg_lower = msg.lower()
                    if len(msg) > 100 or not any(phrase in msg_lower for phrase in greeting_phrases):
                        all_greetings = False
                        break
                        
                if all_greetings:
                    return "Initial greetings only"
            
            # Generate a meaningful mini-summary with the LLM
            mini_summarization_prompt = f"""
You are analyzing a conversation session to provide a short, meaningful summary.

Guidelines:
1. Focus on the SPECIFIC topics, concepts, and tasks discussed - be concrete and descriptive
2. Mention particular technologies, code elements, or problems addressed
3. Include ACTION VERBS that describe what was done or requested (discussed, implemented, fixed, searched)
4. Ignore generic greetings and pleasantries
5. If the conversation is just initial greetings with no substance, say "Initial greetings only"
6. Start with a strong topic-focused verb like "Discussed", "Implemented", "Fixed", "Explored"
7. YOU MUST ANALYZE ALL MESSAGES, not just the first few
8. If user requested information about a topic, mention that specific topic
9. This session has {message_count} total messages, and you're seeing {len(conversation_sample)} of them

CONVERSATION (from session {session_uuid[:8]}...):
{conversation_text}

BRIEF SUMMARY (1-3 sentences, be specific about content discussed):
"""
            
            # Get a temporary PromptChain using the property
            temp_chain = self.prompt_chain
            mini_summary_response = await temp_chain.process_prompt_async(mini_summarization_prompt)
            
            # Clean up the response
            mini_summary = mini_summary_response.strip()
            mini_summary = re.sub(r'^[#\-*]+\s*', '', mini_summary)  # Remove markdown headers/bullets
            mini_summary = re.sub(r'\n+', ' ', mini_summary)  # Replace newlines with spaces
            
            # Ensure it's truly brief (truncate if needed)
            if len(mini_summary) > 200:
                mini_summary = mini_summary[:197] + "..."
            
            # Verify we're not just returning a greeting - improved check
            if len(mini_summary) < 50 and any(greeting in mini_summary.lower() for greeting in greeting_phrases):
                # Double-check if there's actually substantive content elsewhere in the conversation
                has_substance = False
                for msg in conversation_sample:
                    if len(msg) > 100 and not any(greeting in msg.lower() for greeting in greeting_phrases):
                        has_substance = True
                        break
                        
                if has_substance:
                    # If there is substance but the LLM returned a greeting, try again with a clearer prompt
                    revised_prompt = f"""
The conversation has substantive content beyond just greetings.

IMPORTANT: IGNORE all greetings completely and focus ONLY on the substantive content.

Your task is to:
1. Identify SPECIFIC topics, technical questions, or problems discussed
2. Begin your summary with a descriptive action verb (Discussed, Explored, Addressed, etc.)
3. Include particular technologies, tools, or concepts mentioned
4. Be concrete and specific about what was actually discussed
5. Avoid generic descriptions like "discussed various topics"

CONVERSATION:
{conversation_text}

BRIEF SUMMARY (1-3 sentences, ONLY about substantive content, be SPECIFIC):
"""
                    mini_summary = await temp_chain.process_prompt_async(revised_prompt)
                    mini_summary = mini_summary.strip()
                    mini_summary = re.sub(r'^[#\-*]+\s*', '', mini_summary)  # Remove markdown headers/bullets
                    mini_summary = re.sub(r'\n+', ' ', mini_summary)  # Replace newlines with spaces
                    
                    if len(mini_summary) > 200:
                        mini_summary = mini_summary[:197] + "..."
                else:
                    mini_summary = "Initial greeting without substantive content"
                
            # Store the generated summary
            self.internal_memory["mini_summaries"][session_uuid] = {
                "timestamp": datetime.now().isoformat(),
                "summary": mini_summary
            }
                
            return mini_summary
            
        except Exception as e:
            logger.error(f"Error generating mini-summary for session {session_uuid}: {e}")
            return f"Error generating summary: {str(e)}"

    def _compare_sessions(self, session_uuids: List[str]) -> Dict[str, Any]:
        """
        Compare multiple sessions to identify relationships and common themes.
        
        Args:
            session_uuids: List of session UUIDs to compare
            
        Returns:
            Dict with comparison results and metadata
        """
        if not self.agent_chain.enable_cache or not self.agent_chain.db_connection:
            return {"success": False, "error": "Cache is not enabled", "relationships": []}
            
        if len(session_uuids) < 2:
            return {"success": False, "error": "Need at least two sessions to compare", "relationships": []}
            
        try:
            cursor = self.agent_chain.db_connection.cursor()
            
            # Get the session ID
            session_id = self.agent_chain.cache_config.get("name", "default")
            
            # Get sample content from each session
            session_contents = {}
            common_terms = set()
            first_session = True
            
            for uuid in session_uuids:
                # Get messages from this session
                cursor.execute(
                    """
                    SELECT content 
                    FROM conversation_entries 
                    WHERE session_id = ? AND session_instance_uuid = ? AND role LIKE 'user%'
                    ORDER BY id
                    LIMIT 10
                    """,
                    (session_id, uuid)
                )
                
                messages = cursor.fetchall()
                if not messages:
                    continue
                    
                # Extract content into a single string
                content = " ".join([msg[0] for msg in messages])
                session_contents[uuid] = content
                
                # Extract significant terms (simple approach)
                # Remove common words, punctuation, etc.
                terms = re.findall(r'\b[a-zA-Z]{4,}\b', content.lower())
                terms = [term for term in terms if term not in ['this', 'that', 'with', 'have', 'what', 'from', 'your', 'will', 'would', 'could', 'should', 'there', 'their', 'about']]
                
                # For the first session, initialize common_terms
                if first_session:
                    common_terms = set(terms)
                    first_session = False
                else:
                    # Find intersection with previous sessions
                    common_terms = common_terms.intersection(set(terms))
            
            # Identify relationships
            relationships = []
            
            # Common themes across all sessions
            if common_terms:
                relationships.append({
                    "type": "common_themes",
                    "description": f"Common themes across sessions: {', '.join(list(common_terms)[:5])}"
                })
                
            # Chronological relationship
            if len(session_uuids) >= 2:
                # Get creation timestamps
                cursor.execute(
                    f"""
                    SELECT session_instance_uuid, created_at 
                    FROM sessions 
                    WHERE session_id = ? AND session_instance_uuid IN ({','.join(['?']*len(session_uuids))})
                    ORDER BY created_at
                    """,
                    [session_id] + session_uuids
                )
                
                timestamps = cursor.fetchall()
                if len(timestamps) >= 2:
                    chronology = []
                    for uuid, timestamp in timestamps:
                        chronology.append({
                            "uuid": uuid,
                            "created_at": timestamp
                        })
                    
                    relationships.append({
                        "type": "chronological",
                        "description": "Sessions in chronological order",
                        "order": chronology
                    })
            
            return {
                "success": True,
                "relationships": relationships,
                "common_terms": list(common_terms)
            }
            
        except Exception as e:
            logger.error(f"Error comparing sessions: {e}")
            return {"success": False, "error": str(e), "relationships": []}

    async def run_async(self, initial_input: str, available_tools, llm_runner, tool_executor):
        """
        Override the AgenticStepProcessor's run_async method to handle command processing.
        This method is called by the PromptChain when executing this step.
        
        Args:
            initial_input: The user's command (after removing @state: prefix)
            available_tools: Tools registered on the parent chain
            llm_runner: Callback function to run the LLM
            tool_executor: Callback function to execute tools
            
        Returns:
            Response after processing the command
        """
        # Store the tool_executor for later use
        self.tool_executor = tool_executor
        
        # Call the parent class's run_async method to handle the command with agentic capabilities
        logger.info(f"StateAgent processing command with AgenticStepProcessor: {initial_input}")
        return await super().run_async(initial_input, available_tools, llm_runner, tool_executor)

    async def list_sessions(self, filter_terms: str = None, all_sessions: bool = True, limit: int = 10) -> str:
        """
        List available sessions, optionally filtered by topic.
        
        Args:
            filter_terms: Optional keywords to filter sessions by topic
            all_sessions: Whether to include all sessions or just those we've interacted with
            limit: Maximum number of sessions to return
            
        Returns:
            Formatted string with list of available sessions
        """
        # Convert the old _list_sessions method result to a formatted string
        sessions_result = self._list_sessions(
            topic_filter=filter_terms if filter_terms else None,
            all_sessions=all_sessions,
            limit=limit
        )
        
        if not sessions_result.get("success", False):
            return f"Error listing sessions: {sessions_result.get('error', 'Unknown error')}"
        
        sessions = sessions_result.get("sessions", [])
        
        # If no sessions found
        if not sessions:
            return "No sessions found. This may be because no conversations have been cached yet."
        
        # Format the response
        response_parts = [f"Found {len(sessions)} session{'s' if len(sessions) > 1 else ''}:"]
        
        # First, generate mini summaries for all sessions that need them
        # We'll do this synchronously to ensure they're available for the response
        for session in sessions:
            session_uuid = session.get("session_instance_uuid", "unknown")
            # Add this session to known sessions
            if session_uuid not in self.internal_memory["known_sessions"]:
                self.internal_memory["known_sessions"].append(session_uuid)
            
            # Generate summary if not already available
            if session_uuid not in self.internal_memory["mini_summaries"]:
                summary = await self._get_or_generate_mini_summary(session_uuid)
                if summary:
                    self.internal_memory["mini_summaries"][session_uuid] = {
                        "timestamp": datetime.now().isoformat(),
                        "summary": summary
                    }
        
        # Now format each session with the available summaries
        for i, session in enumerate(sessions, 1):
            session_uuid = session.get("session_instance_uuid", "unknown")
            created_at = session.get("created_at", "unknown date")
            # Try to get a simple date
            if "T" in created_at:
                created_at = created_at.split("T")[0]
            
            # Get mini summary - now it should be available for all sessions
            mini_summary = "No summary available"
            if session_uuid in self.internal_memory["mini_summaries"]:
                mini_summary = self.internal_memory["mini_summaries"][session_uuid]["summary"]
            
            # Format entry - show full UUID and make it clear this is the session ID
            response_parts.append(f"\n{i}. **Session ID**: {session_uuid} ({created_at})")
            
            # Add mini summary if available
            if mini_summary:
                response_parts.append(f"   **Content**: {mini_summary}")
            
            # Add message count if available
            message_count = session.get("message_count", 0)
            if message_count:
                response_parts.append(f"   **Messages**: {message_count}")
        
        # Add actions
        response_parts.append("\n**Actions you can take:**")
        response_parts.append("- Load a session: `@state: load session [Session ID]`")
        response_parts.append("- Summarize a session: `@state: summarize session [Session ID]`")
        response_parts.append("- Search within these sessions: `@state: find conversations about [topic]`")
        
        return "\n".join(response_parts)
    
    async def search_conversations(self, search_terms: str, search_all_instances: bool = True, max_results: int = 20) -> str:
        """
        Search across conversation sessions for content matching the search terms.
        
        Args:
            search_terms: Terms to search for in conversation content
            search_all_instances: Whether to search across all instances or just the current one
            max_results: Maximum number of matching entries to return
            
        Returns:
            Formatted string with search results
        """
        if not search_terms:
            return "Please specify what you'd like to search for in the conversation history."
        
        # Search across all sessions
        search_results = self._search_sessions(search_terms, search_all_instances=search_all_instances, max_results=max_results)
        
        if not search_results.get("success", False):
            return f"Error searching sessions: {search_results.get('error', 'Unknown error')}"
        
        # Track search in history (this updates both internal memory and global history)
        await self.track_search_in_history(search_terms, search_results)
        
        # If no matches were found
        if len(search_results.get("matches", [])) == 0:
            return f"I couldn't find any conversations about '{search_terms}'. Would you like to try a different search term?"
        
        # Format the search results
        matches = search_results.get("matches", [])
        
        # Group matches by session
        sessions = {}
        for match in matches:
            session_uuid = match.get("session_instance_uuid")
            if session_uuid not in sessions:
                sessions[session_uuid] = []
            sessions[session_uuid].append(match)
        
        # Format the response
        response_parts = [f"Found {len(matches)} matches for '{search_terms}' across {len(sessions)} sessions:"]
        
        for session_uuid, session_matches in sessions.items():
            # Store this session in known_sessions if not already there
            if session_uuid not in self.internal_memory["known_sessions"]:
                self.internal_memory["known_sessions"].append(session_uuid)
            
            # Set as last mentioned session
            self.internal_memory["last_mentioned_session"] = session_uuid
                
            response_parts.append(f"\n## Session ID: {session_uuid} ({len(session_matches)} matches)")
            
            # Get or generate a mini-summary for this session
            mini_summary = await self._get_or_generate_mini_summary(session_uuid)
            if mini_summary:
                response_parts.append(f"**Session Summary**: {mini_summary}")
            
            # Add a few sample matches from this session
            for i, match in enumerate(session_matches[:3]):  # Limit to 3 matches per session
                role = match.get("role", "")
                # Format role to show agent name if available
                if ":" in role and role.startswith("assistant:"):
                    role_parts = role.split(":", 1)
                    display_role = f"{role_parts[0]} ({role_parts[1]})"
                else:
                    display_role = role
                    
                timestamp = match.get("timestamp", "").split("T")[0]
                snippet = match.get("snippet", match.get("content", "")[:100] + "...")
                response_parts.append(f"{i+1}. **{display_role}** ({timestamp}): {snippet}")
            
            if len(session_matches) > 3:
                response_parts.append(f"...and {len(session_matches) - 3} more matches in this session.")
        
        response_parts.append("\nOptions:")
        response_parts.append("- Load a session: 'load session [Session ID]'")
        response_parts.append("- Summarize a session: 'summarize session [Session ID]'")
        response_parts.append("- Continue searching: 'search for [new terms]'")
        
        return "\n".join(response_parts)

    async def load_session(self, session_uuid: str, mode: str = "replace_current") -> str:
        """
        Load a previous conversation session by its UUID.
        
        Args:
            session_uuid: The UUID of the session instance to load
            mode: How to handle the loaded session ('replace_current', 'append', 'search_only')
            
        Returns:
            Message indicating the result of the load operation
        """
        # Check if they're referring to "the session we just found" or similar
        if session_uuid.lower() in ["last", "previous", "that"]:
            # Use the last mentioned session from memory
            if self.internal_memory["last_mentioned_session"]:
                session_uuid = self.internal_memory["last_mentioned_session"]
            else:
                return "I don't have a specific session in mind. Please specify a session UUID or search for a session first."
                
        # Validate the session exists
        if not self._validate_session_exists(session_uuid):
            return f"Session with UUID {session_uuid} not found. Please check the UUID or search for available sessions."
        
        # Load the session using AgentChain's load_session method
        result = self._load_session(session_uuid, mode=mode)
        
        if not result.get("success", False):
            return f"Error loading session: {result.get('error', 'Unknown error')}"
        
        # Update internal memory
        if session_uuid not in self.internal_memory["known_sessions"]:
            self.internal_memory["known_sessions"].append(session_uuid)
        self.internal_memory["last_mentioned_session"] = session_uuid
        
        return f"Successfully loaded session {session_uuid}. Loaded {result.get('entries_loaded', 0)} conversation entries into the current context. You can now continue the conversation from this loaded session."
        
    async def summarize_session(self, session_uuid: str) -> str:
        """
        Generate a summary of a specific conversation session.
        
        Args:
            session_uuid: UUID of the session to summarize
            
        Returns:
            A detailed summary of the session content
        """
        # Check if they're referring to "the session we just found" or similar
        if session_uuid.lower() in ["last", "previous", "that"]:
            # Use the last mentioned session from memory
            if self.internal_memory["last_mentioned_session"]:
                session_uuid = self.internal_memory["last_mentioned_session"]
            else:
                return "I don't have a specific session in mind. Please specify a session UUID or search for a session first."
                
        # Validate the session exists
        if not self._validate_session_exists(session_uuid):
            return f"Session with UUID {session_uuid} not found. Please check the UUID or search for available sessions."
        
        # Check if we already have a cached summary
        if session_uuid in self.internal_memory["session_summaries"]:
            cached_summary = self.internal_memory["session_summaries"][session_uuid]
            # Check if the cached summary is recent (within the last hour)
            cache_time = datetime.fromisoformat(cached_summary.get("timestamp", "2000-01-01T00:00:00"))
            if (datetime.now() - cache_time).total_seconds() < 3600:  # Less than an hour old
                return cached_summary.get("summary", "Summary not available.")
        
        # Get the session data in search_only mode
        session_data = self._load_session(session_uuid, mode="search_only")
        
        if not session_data.get("success", False):
            return f"Error retrieving session data: {session_data.get('error', 'Unknown error')}"
        
        # Update internal memory
        if session_uuid not in self.internal_memory["known_sessions"]:
            self.internal_memory["known_sessions"].append(session_uuid)
        self.internal_memory["last_mentioned_session"] = session_uuid
        
        # Generate a summary using the LLM
        entries = session_data.get("entries", [])
        
        if not entries:
            return f"Session {session_uuid} exists but contains no conversation entries."
        
        # Format the conversation for summarization
        conversation = []
        total_tokens = 0
        max_tokens = 16000  # Token limit for context
        
        for entry in entries:
            role = entry.get("role", "")
            # Format role to show agent name if available
            if ":" in role and role.startswith("assistant:"):
                role_parts = role.split(":", 1)
                display_role = f"{role_parts[0]} ({role_parts[1]})"
            else:
                display_role = role
            
            content = entry.get("content", "")
            message_text = f"{display_role}: {content}"
            
            # Count tokens for this message
            message_tokens = count_tokens(message_text)
            
            # Check if adding this message would exceed token limit
            if total_tokens + message_tokens > max_tokens:
                # Add a note about truncation
                conversation.append("...\n[Conversation truncated due to length]")
                break
            
            conversation.append(message_text)
            total_tokens += message_tokens
        
        conversation_text = "\n\n".join(conversation)
        logger.info(f"Summarizing session {session_uuid} with {total_tokens} tokens from {len(conversation)} messages")
        
        # Generate the summary with the LLM
        summarization_prompt = f"""
Please provide a concise summary of the following conversation session.
Focus on:
1. Main topics discussed
2. Key questions asked and answers provided
3. Any decisions or conclusions reached
4. Technical concepts or code examples mentioned
5. DO NOT focus on greetings - only substantive content

Format the summary with clear sections and bullet points where appropriate.

CONVERSATION SESSION {session_uuid}:
{conversation_text}

SUMMARY:
"""
        
        # Use a separate PromptChain for summarization to avoid confusing the agentic step processor
        summarizer = PromptChain(
            models=[{"name": "openai/gpt-4o-mini", "params": {"temperature": 0.2}}],
            instructions=[summarization_prompt],
            verbose=self.verbose
        )
        
        summary_response = await summarizer.process_prompt_async("")
        
        # Cache the summary in memory
        self.internal_memory["session_summaries"][session_uuid] = {
            "timestamp": datetime.now().isoformat(),
            "summary": summary_response,
            "message_count": len(entries)
        }
        
        # Append options to the summary
        full_response = summary_response + "\n\nOptions:\n- Load this session: 'load session " + session_uuid + "'\n- Continue with current session: 'continue'\n- Search for related sessions: 'search for [terms]'"
        
        return full_response
    
    async def compare_sessions(self, session_uuids: List[str]) -> str:
        """
        Compare multiple sessions to identify relationships and common themes.
        
        Args:
            session_uuids: List of session UUIDs to compare
            
        Returns:
            A detailed comparison of the sessions
        """
        # If we have less than 2 UUIDs and there's a reference to "recent" sessions
        if len(session_uuids) < 2:
            # Use the most recent sessions from internal memory
            known_sessions = self.internal_memory["known_sessions"]
            if len(known_sessions) >= 2:
                session_uuids = known_sessions[-2:]  # Use the 2 most recent
            else:
                return "I need at least 2 sessions to compare. Please specify session UUIDs or search for sessions first."
            
        # Validate all sessions exist
        for session_uuid in session_uuids:
            if not self._validate_session_exists(session_uuid):
                return f"Session with UUID {session_uuid} not found. Please check the UUID or search for available sessions."
        
        # Compare the sessions
        comparison = self._compare_sessions(session_uuids)
        
        if not comparison.get("success", False):
            return f"Error comparing sessions: {comparison.get('error', 'Unknown error')}"
        
        # Update internal memory to include all sessions being compared
        for session_uuid in session_uuids:
            if session_uuid not in self.internal_memory["known_sessions"]:
                self.internal_memory["known_sessions"].append(session_uuid)
        
        # Generate a comprehensive inter-session summary using the LLM
        session_summaries = []
        
        for session_uuid in session_uuids:
            # Get a summary for each session
            mini_summary = await self._get_or_generate_mini_summary(session_uuid)
            uuid_short = session_uuid[:8]
            session_summaries.append(f"- Session {uuid_short}...: {mini_summary}")
        
        relationships = comparison.get("relationships", [])
        common_terms = comparison.get("common_terms", [])
        
        inter_session_summarization_prompt = f"""
Please analyze the relationship between these conversation sessions and provide a concise summary of how they connect.

SESSION SUMMARIES:
{chr(10).join(session_summaries)}

IDENTIFIED RELATIONSHIPS:
{chr(10).join([rel.get("description", "") for rel in relationships])}

COMMON THEMES:
{', '.join(common_terms[:10]) if common_terms else 'No common themes identified'}

Provide a brief (3-5 sentences) analysis of how these sessions relate to each other and what insights might be gained by considering them together. Include mentions of progression, thematic connections, or contextual relationships.

INTER-SESSION ANALYSIS:
"""
        
        # Use a separate PromptChain for the inter-session analysis
        analyzer = PromptChain(
            models=[{"name": "openai/gpt-4o-mini", "params": {"temperature": 0.2}}],
            instructions=[inter_session_summarization_prompt],
            verbose=self.verbose
        )
        
        inter_session_summary = await analyzer.process_prompt_async("")
        
        # Format the response
        response_parts = [f"# Comparison of {len(session_uuids)} Sessions"]
        
        # Add the mini-summaries
        response_parts.append("\n## Session Summaries:")
        for summary in session_summaries:
            response_parts.append(summary)
        
        # Add the inter-session analysis
        response_parts.append("\n## Relationship Analysis:")
        response_parts.append(inter_session_summary)
        
        # Add common themes if any
        if common_terms:
            response_parts.append("\n## Common Themes:")
            response_parts.append(f"Common topics across sessions: {', '.join(common_terms[:10])}")
        
        # Add chronological relationship if available
        for relationship in relationships:
            if relationship.get("type") == "chronological" and "order" in relationship:
                response_parts.append("\n## Chronological Order:")
                chronology = relationship.get("order", [])
                for i, entry in enumerate(chronology):
                    uuid = entry.get("uuid", "")
                    created_at = entry.get("created_at", "").split("T")[0]
                    response_parts.append(f"{i+1}. Session {uuid[:8]}... (Created: {created_at})")
        
        response_parts.append("\nOptions:")
        response_parts.append("- Load a session: 'load session [UUID]'")
        response_parts.append("- Search within these sessions: 'search for [terms]'")
        
        return "\n".join(response_parts)

    async def get_sessions_markdown_table(self, filter_terms: str = None, all_sessions: bool = True, limit: int = 10) -> str:
        """
        Generate a markdown table listing sessions with their summaries and message counts.
        
        Args:
            filter_terms: Optional keywords to filter sessions by topic
            all_sessions: Whether to include all sessions or just those we've interacted with
            limit: Maximum number of sessions to return
            
        Returns:
            Markdown-formatted table with session information
        """
        # Get the sessions
        sessions_result = self._list_sessions(
            topic_filter=filter_terms if filter_terms else None,
            all_sessions=all_sessions,
            limit=limit
        )
        
        if not sessions_result.get("success", False):
            return f"Error listing sessions: {sessions_result.get('error', 'Unknown error')}"
        
        sessions = sessions_result.get("sessions", [])
        
        # If no sessions found
        if not sessions:
            return "No sessions found. This may be because no conversations have been cached yet."
        
        # Generate session summaries proactively by reading all session messages
        logger.info(f"Generating summaries for {len(sessions)} sessions for table format")
        
        if not self.agent_chain.enable_cache or not self.agent_chain.db_connection:
            return "No database connection available for session listing"
            
        cursor = self.agent_chain.db_connection.cursor()
        db_name = self.agent_chain.cache_config.get("name", "default")
        
        for session in sessions:
            session_uuid = session.get("session_instance_uuid", "unknown")
            
            # Add this session to known sessions
            if session_uuid not in self.internal_memory["known_sessions"]:
                self.internal_memory["known_sessions"].append(session_uuid)
            
            # Check if we have a cached summary that's generic and should be regenerated
            should_regenerate = False
            if session_uuid in self.internal_memory["mini_summaries"]:
                cached_summary = self.internal_memory["mini_summaries"][session_uuid]
                summary_text = ""
                
                if isinstance(cached_summary, dict):
                    summary_text = cached_summary.get("summary", "")
                else:
                    summary_text = cached_summary
                
                # Force regeneration if it's a generic summary
                if (
                    summary_text.startswith("Conversation with") or
                    summary_text in ["Initial greetings only", "No summary available", "Empty session", 
                                   "Initial greeting without substantive content"]
                ):
                    should_regenerate = True
                    logger.info(f"Will regenerate generic summary for session {session_uuid}")
            
            # Generate or regenerate the summary
            if should_regenerate or session_uuid not in self.internal_memory["mini_summaries"]:
                # Generate a new detailed summary
                summary = await self._get_or_generate_mini_summary(session_uuid)
                if summary:
                    self.internal_memory["mini_summaries"][session_uuid] = {
                        "timestamp": datetime.now().isoformat(),
                        "summary": summary
                    }
        
        # Now format as a markdown table
        table_header = "| Session ID | Summary | Messages |\n| --- | --- | --- |"
        table_rows = []
        
        for session in sessions:
            session_uuid = session.get("session_instance_uuid", "unknown")
            message_count = session.get("message_count", 0)
            
            # Get mini summary - now it should be available for all sessions
            mini_summary = "No summary available"
            if session_uuid in self.internal_memory["mini_summaries"]:
                if isinstance(self.internal_memory["mini_summaries"][session_uuid], dict):
                    mini_summary = self.internal_memory["mini_summaries"][session_uuid].get("summary", "No summary available")
                else:
                    mini_summary = self.internal_memory["mini_summaries"][session_uuid]
            
            # Check if the summary is just a generic greeting
            if (
                # Only replace if the ENTIRE summary is a generic greeting (stricter check)
                mini_summary.lower() in [
                    "initial greetings only",
                    "initial greeting without substantive content",
                    "no summary available",
                    "empty session"
                ] or (
                    # Or if it contains greeting phrases AND is very short AND doesn't contain specific content markers
                    any(greeting in mini_summary.lower() for greeting in [
                        "hello", "hi there", "how can i assist", "how may i help", 
                        "initial greeting", "welcome"
                    ]) and 
                    len(mini_summary) < 50 and
                    not any(content_marker in mini_summary.lower() for content_marker in [
                        "discuss", "about", "question", "problem", "implement", "fix", "feature",
                        "code", "error", "bug", "document", "session", "search"
                    ])
                )
            ):
                # For these, try to provide something more meaningful
                if message_count > 0:
                    mini_summary = f"Conversation with {message_count} messages"
            
            # Escape pipe characters in the summary to avoid breaking the table
            mini_summary = mini_summary.replace("|", "\\|")
            
            # Create the table row - use abbreviated UUID for readability
            table_rows.append(f"| {session_uuid} | {mini_summary} | {message_count} |")
        
        # Combine the header and rows
        table = f"{table_header}\n" + "\n".join(table_rows)
        
        # Add actions
        actions = "\n\n**Actions you can take:**\n"
        actions += "- Load a session: `@state: load session [Session ID]`\n"
        actions += "- Summarize a session: `@state: summarize session [Session ID]`\n"
        actions += "- Search within these sessions: `@state: find conversations about [topic]`"
        
        return f"Here are the available sessions along with their summaries:\n\n{table}{actions}"

    async def list_sessions_table(self, filter_terms: str = None, all_sessions: bool = True, limit: int = 10) -> str:
        """
        Format available sessions as a markdown table with summaries and message counts.
        
        Args:
            filter_terms: Optional keywords to filter sessions by topic
            all_sessions: Whether to include all sessions or just those we've interacted with
            limit: Maximum number of sessions to return
            
        Returns:
            Markdown table listing sessions with summaries and message counts
        """
        return await self.get_sessions_markdown_table(filter_terms, all_sessions, limit)

    async def track_search_in_history(self, search_term: str, search_results: Dict[str, Any]) -> None:
        """
        Track search queries in the agent's internal memory only.
        
        Args:
            search_term: The search term used for the query
            search_results: The results dictionary from _search_sessions
            
        Returns:
            None (modifies internal memory only)
        """
        # Add to internal memory for agent's reference
        self.internal_memory["recent_searches"].append({
            "timestamp": datetime.now().isoformat(),
            "query": search_term,
            "results": search_results,
            "result_count": len(search_results.get("matches", []))
        })
        
        return None
        
    async def add_search_to_global_history(self, search_term: str = None) -> str:
        """
        Add the most recent search (or a specific search term) to the global conversation history.
        
        Args:
            search_term: Optional specific search term to add. If None, uses most recent search.
            
        Returns:
            Confirmation message
        """
        # Find the relevant search in internal memory
        if search_term:
            # Find the specific search term
            matching_searches = [s for s in self.internal_memory["recent_searches"] 
                               if s.get("query", "").lower() == search_term.lower()]
            if not matching_searches:
                return f"No search for '{search_term}' found in memory. Please search for this term first."
            target_search = matching_searches[-1]  # Use the most recent match if multiple
        else:
            # Use the most recent search
            if not self.internal_memory["recent_searches"]:
                return "No recent searches found in memory. Please perform a search first."
            target_search = self.internal_memory["recent_searches"][-1]
        
        # Extract details from the target search
        search_term = target_search.get("query", "unknown")
        search_results = target_search.get("results", {})
        match_count = len(search_results.get("matches", []))
        session_count = len({match.get("session_instance_uuid") for match in search_results.get("matches", [])})
        
        # Format the summary for global history
        summary_text = f"Search query: '{search_term}'\n"
        summary_text += f"Found {match_count} matches across {session_count} sessions.\n"
        
        # Add brief samples of what was found (limited to first 3 for brevity)
        if match_count > 0:
            summary_text += "\nSample matches:\n"
            for i, match in enumerate(search_results.get("matches", [])[:3]):
                snippet = match.get("snippet", "")[:100] + "..." if len(match.get("snippet", "")) > 100 else match.get("snippet", "")
                summary_text += f"{i+1}. {snippet}\n"
        
        # Create entry as if the agent responded to a search request
        search_entry = {
            "role": "assistant:state_agent",
            "content": summary_text,
            "timestamp": datetime.now().isoformat(),
            "metadata": {"search_term": search_term, "is_search_result": True}
        }
        
        # Add to global history
        self.agent_chain._conversation_history.append(search_entry)
        
        return f"Search results for '{search_term}' added to the global conversation history."

# Function to create a state agent PromptChain that can be added to an AgentChain
def create_state_agent(agent_chain: AgentChain, verbose: bool = False) -> PromptChain:
    """
    Create a PromptChain for the state agent that can be added to an AgentChain.
    
    Args:
        agent_chain: The AgentChain this agent will work with
        verbose: Whether to enable verbose logging
        
    Returns:
        A configured PromptChain for the state agent
    """
    # Create the StateAgent instance
    state_agent = StateAgent(agent_chain, verbose)
    
    # Create a PromptChain that wraps the AgenticStepProcessor
    state_agent_chain = PromptChain(
        models=[],  # No models needed since AgenticStepProcessor handles this internally
        instructions=[state_agent],  # Use the AgenticStepProcessor directly as an instruction
        verbose=verbose
    )
    
    # Register the tools on the chain
    state_agent_chain.add_tools(state_agent.TOOL_SCHEMAS)
    
    # Register the tool functions
    state_agent_chain.register_tool_function(state_agent.list_sessions)
    state_agent_chain.register_tool_function(state_agent.list_sessions_table)
    state_agent_chain.register_tool_function(state_agent.search_conversations)
    state_agent_chain.register_tool_function(state_agent.load_session)
    state_agent_chain.register_tool_function(state_agent.summarize_session)
    state_agent_chain.register_tool_function(state_agent.compare_sessions)
    state_agent_chain.register_tool_function(state_agent.add_search_to_global_history)
    
    return state_agent_chain 